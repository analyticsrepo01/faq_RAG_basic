import {
  __async
} from "./chunk-WFI2LP4G.mjs";
import {
  defineEmbedder,
  embedderRef
} from "@genkit-ai/ai/embedder";
import { z } from "zod";
import { predictModel } from "./predict.js";
const TaskTypeSchema = z.enum([
  "RETRIEVAL_DOCUMENT",
  "RETRIEVAL_QUERY",
  "SEMANTIC_SIMILARITY",
  "CLASSIFICATION",
  "CLUSTERING"
]);
const TextEmbeddingGeckoConfigSchema = z.object({
  /**
   * The `task_type` parameter is defined as the intended downstream application to help the model
   * produce better quality embeddings.
   **/
  taskType: TaskTypeSchema.optional(),
  title: z.string().optional()
});
const textEmbeddingGecko003 = embedderRef({
  name: "vertexai/textembedding-gecko@003",
  configSchema: TextEmbeddingGeckoConfigSchema,
  info: {
    dimensions: 768,
    label: "Vertex AI - Text Embedding Gecko",
    supports: {
      input: ["text"]
    }
  }
});
const textEmbeddingGecko002 = embedderRef({
  name: "vertexai/textembedding-gecko@002",
  configSchema: TextEmbeddingGeckoConfigSchema,
  info: {
    dimensions: 768,
    label: "Vertex AI - Text Embedding Gecko",
    supports: {
      input: ["text"]
    }
  }
});
const textEmbeddingGecko001 = embedderRef({
  name: "vertexai/textembedding-gecko@001",
  configSchema: TextEmbeddingGeckoConfigSchema,
  info: {
    dimensions: 768,
    label: "Vertex AI - Text Embedding Gecko (Legacy)",
    supports: {
      input: ["text"]
    }
  }
});
const textEmbeddingGecko = textEmbeddingGecko003;
const SUPPORTED_EMBEDDER_MODELS = {
  "textembedding-gecko@003": textEmbeddingGecko003,
  "textembedding-gecko@002": textEmbeddingGecko002,
  "textembedding-gecko@001": textEmbeddingGecko001
  //'textembeddding-gecko-multilingual@001': textEmbeddingGeckoMultilingual001,
};
function textEmbeddingGeckoEmbedder(name, client, options) {
  const embedder = SUPPORTED_EMBEDDER_MODELS[name];
  const predict = predictModel(
    client,
    options,
    name
  );
  return defineEmbedder(
    {
      name: embedder.name,
      configSchema: embedder.configSchema,
      info: embedder.info
    },
    (input, options2) => __async(this, null, function* () {
      const response = yield predict(
        input.map((i) => {
          return {
            content: i.text(),
            task_type: options2 == null ? void 0 : options2.taskType,
            title: options2 == null ? void 0 : options2.title
          };
        })
      );
      return {
        embeddings: response.predictions.map((p) => ({
          embedding: p.embeddings.values
        }))
      };
    })
  );
}
export {
  SUPPORTED_EMBEDDER_MODELS,
  TaskTypeSchema,
  TextEmbeddingGeckoConfigSchema,
  textEmbeddingGecko,
  textEmbeddingGecko001,
  textEmbeddingGecko002,
  textEmbeddingGecko003,
  textEmbeddingGeckoEmbedder
};
//# sourceMappingURL=embedder.mjs.map